<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>PH Twitter Fake News Analysis</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="#top">Top</a></li>
					<li><a href="#overview">Overview</a></li>
					<li><a href="#data">Data</a></li>
					<li><a href="#methods">Methods</a></li>
					<li><a href="#results">Results</a></li>
					<li><a href="#team">Team</a></li>
				</ul>
			</nav>

		<!-- Home -->
			<article id="top" class="wrapper style1">
				<div class="container">
					<div class="row">
						<div class="col-4 col-5-large col-12-medium">
							<span class="image fit"><img src="images/logo_1.png" alt="" /></span>
						</div>
						<div class="col-8 col-7-large col-12-medium">
							<header>
								<h1>Hi. We are <strong>DATA ATLAS</strong>.</h1>
							</header>
							<p>We are conducting an analysis on tweets from 2016-2022 to determine events that may have triggered the spread of mis/disinformation regarding tuob and herbal medicines' ability to cure COVID-19.</em> We aim to process and investigate the data from these tweets to hopefully gain more insight about the proliferation of misinformation on Twitter during the pandemic.</p>
							<p>Data Science Team</p>
							<ul style="list-style-type:none; margin-top:-30px;">
							  <li>Francis Mamuyac Albarracin, WFU</li>
							  <li>Zachary R. Nabong, WFW</li>
							  <li>Jeremy King L. Tsang, WFW</li>
							</ul>
						</div>
					</div>
				</div>
			</article>

		<!-- Overview -->
			<article id="overview" class="wrapper style2">
				<div class="container">
					<header>
						<h2>Why are we doing this?</h2>
					</header>
					<div class="row aln-center">
						<div class="col-12">
							<section class="box style1">
								<h3>Motivation</h3>
								<p>The circulation mis/disinformation on COVID-19 has been shown to increase public anxiety and distrust (Greene & Murphy, 2021). The warp in public perception and public distrust can lead to serious repercussions given the circumstances, as sick individuals may delay seeking proper medical treatment due to their false belief on alternative medicines, thus putting their life in greater danger.</p>
							</section>
						</div>	
						<div class="col-4 col-6-medium col-12-small">
							<section class="box style1">
								<span class="icon featured fa-comments"></span>
								<h3>Research Question</h3>
								<p>What events have triggered the spread of mis/disinformation about tuob and herbal medicines being able to cure COVID-19?</p>
							</section>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<section class="box style1">
								<span class="icon solid featured fa-bullseye"></span>
								<h3>Hypothesis</h3>
								<p>The timing of the endorsements of famous personalities correlates to the spread of mis/disinformation on alternative cures for COVID-19.</p>
							</section>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<section class="box style1">
								<span class="icon featured fa-times-circle"></span>
								<h3>Null Hypothesis</h3>
								<p>The timing of the endorsements of famous personalities has no correlation to the spread of mis/disinformation on alternative cures for COVID-19.</p>
							</section>
						</div>
						<div class="col-12">
							<section class="box style1">
								<h3>Action Plan</h3>
								<p>Analyze the frequency and posting time of mis/disinformation tweets about tuob and herbal medicines being able to cure COVID-19.</p>
							</section>
						</div>
					</div>
			</article>

		<!-- Data -->
			<article id="data" class="wrapper style1">
				<div class="container">
					<header>
						<h2>We mined Twitter for fake news data on COVID-19 alternative remedies.</h2>
					</header>
					<div class="row">
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic01.jpg" alt="" /></a>
								<h3><a href="#">Topic</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic02.jpg" alt="" /></a>
								<h3><a href="#">Keywords</a></h3>
								<p>Ornare nulla proin odio consequat..</p>
							</article>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic03.jpg" alt="" /></a>
								<h3><a href="#">Tools</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
					</div>
					<footer>
						<p>Curious of our data?</p>
						<a href="https://docs.google.com/spreadsheets/d/1soZQfU-6A4gmQRhCd_UsMKVMqVqoaEwg0zM01--WByw/edit#gid=107810933" class="button large scrolly" target="_blank">Take a look at it here!</a>
					</footer>
				</div>
			</article>

		<!-- Data exploration -->
			<article id="data-exploration" class="wrapper style1">
				<div class="container">
					<header>
						<h2>Here is how we explored the data,</h2>
					</header>
					<div class="container" id="preprocessing" style="text-align:left; margin-left: 40px;">
						<h3>1. Preprocessing</h3>
						<p>Before we begin exploring the data, preprocessing techniques must first be applied in order to ensure the cleanliness of the data.</p>
						<div class="container" style="text-align:left;">
							<h3>1.a. Handling missing values</h3>
							<p>When looking for missing values, we can observe that `Account bio`, `Location`, `Tweet Translated`, `Screenshot`, `Views`, `Rating`, `Remarks`, `Reviewer`, `Review` are all listed.</p>
							<pre class="code-block">print("Columns with missing/nan values:")
print("Data set:", df_dataset.columns[df_dataset.isna().any()].tolist())</pre>
							<figure>
								<img src="1a-output1.png" alt="" srcset="" style="width: 100%">
								<figcaption>Codeblock output</figcaption>
							</figure>
							<p>Some of these columns, including `Tweet Translated`, `Screenshot`, `Views`, `Rating`, `Remarks`, `Reviewer`, and `Review`, are optional columns that we have opted not to fill out during data collection.</p>
							<p>On the other hand, `Account bio` and `Location` are columns with missing values given that Twitter users may opt to leave these fields blank. Given that there is already a limited amount of data, dropping the samples is not ideal. In addition, `Account bio` and `Location` are not relevant variables for what we want to analyse later on. Therefore, given the irrelevancy of said columns and small number of samples, we instead choose to drop the columns instead of the samples.</p>
							<pre class="code-block">df_dataset = df_dataset.drop(['Account bio', 'Location', 'Tweet Translated', 'Screenshot', 'Rating', 'Remarks','Reviewer', 'Review', 'Views'], axis=1)</pre>
							<p>In addition to columns with missing values, we can also look to drop columns that are completely filled up but are irrelevant to analysis. These include `ID`, `Timestamp`, `Tweet URL`, `Group`, `Collector`, `Category`, `Topic`, `Keywords`, `Account handle`, `Account name`, `Joined`, `Tweet Type`, and `Reasoning`.</p>
							<pre class="code-block">df_dataset = df_dataset.drop(['ID', 'Timestamp', 'Group', 'Collector', 'Category', 'Topic', 'Keywords', 'Reasoning', 'Tweet URL', 'Account handle', 'Account name', 'Joined', 'Tweet Type'], axis=1)</pre>
							<p>With that, we are left with a much more compact dataset with only 10 columns, while maintaining a total of 150 samples.</p>
							<pre class="code-block">df_dataset.head(10).style.set_properties(**{'text-align': 'left'})</pre>
							<figure>
								<img src="1a-output2.png" alt="" srcset="" style="width: 100%">
								<figcaption>The first 10 rows of the dataframe</figcaption>
							</figure>
						</div>
						<div class="container">
							<h3>1.b. Handling outliers</h3>
							<p>After handling missing values, we turn our attention into possible outlier values. While we were able to preserve our samples by dropping columns when handling missing values, the same cannot be done for outlier data. These data can heavily affect our analysis and results later on.</p>
							<p>Using the following code, we begin by looking into our outlier data based on each variable.</p>
							<pre class="code-block">from sklearn.preprocessing import StandardScaler
import seaborn as sns

# Standardize the features to get z-scores
df_scaled = df_dataset.copy(deep=True)
scaler = StandardScaler()
df_scaled[['Followers']] = scaler.fit_transform(df_scaled[['Followers']])

followers_zscore = df_scaled['Followers']
n_out1 = len(followers_zscore[abs(followers_zscore) > 1])
n_out2 = len(followers_zscore[abs(followers_zscore) > 2])
n_out3 = len(followers_zscore[abs(followers_zscore) > 3])
print(f"Number of outliers in 'Followers' (std=1): {n_out1}")
print(f"Number of outliers in 'Followers' (std=2): {n_out2}")
print(f"Number of outliers in 'Followers' (std=3): {n_out3}")

# Define function for coloring bars
def color_bars(ax, df):
	for i in range(len(df)):
		val = abs(df.loc[i, 'Followers'])
		if val <= 1:
			color = 'b'
		elif val <= 2:
			color = 'g'
		elif val <= 3:
			color = 'y'
		else:
			color = 'r'
		ax.get_children()[i].set_color(color)

# Create a figure with two subplots
fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(16, 12))

# Plot the Followers distribution
sns.barplot(x=df_scaled.index, y=df_scaled['Followers'], ax=ax1)

sns.despine(ax=ax1)
ax1.set(title='Followers Outliers', xlabel='Sample', ylabel='Followers (z-score)')
ax1.set_xticks([0, len(df_scaled)-1])
ax1.axhline(y=3, xmin=-0.5, xmax=len(df_scaled)-0.5, color='red', alpha=0.5, ls='--') # Standard deviation lines
ax1.axhline(y=-3, xmin=-0.5, xmax=len(df_scaled)-0.5, color='red', alpha=0.5, ls='--')
color_bars(ax1, df_scaled) # Color the bars

# Plot the Followers distribution, but sorted
df_scaled_sorted = df_scaled.sort_values(['Followers']).reset_index(drop=True)
sns.barplot(x=df_scaled_sorted.index, y=df_scaled_sorted['Followers'], ax=ax2)

sns.despine(ax=ax2)
ax2.set(title='Followers Outliers', xlabel='Sample (sorted)', ylabel='Followers (z-score)')
ax2.set_xticks([0, len(df_scaled_sorted)-1])
ax2.axhline(y=3, xmin=-0.5, xmax=len(df_scaled_sorted)-0.5, color='red', alpha=0.5, ls='--') # Standard deviation lines
ax2.axhline(y=-3, xmin=-0.5, xmax=len(df_scaled_sorted)-0.5, color='red', alpha=0.5, ls='--')
color_bars(ax2, df_scaled_sorted) # Color the bars

plt.tight_layout()
plt.show()</pre>
							<figure>
								<img src="1b-output1.png" alt="" style="width: 100%">
								<img src="1b-output2.png" alt="" style="width: 100%">
								<img src="1b-output3.png" alt="" style="width: 100%">
								<img src="1b-output4.png" alt="" style="width: 100%">
								<figcaption>Followers, Likes, Replies, and Retweets distributions</figcaption>
							</figure>
							<p>We can observe that outlier data do exist in our dataset. Even more concerning is the fact that these outlier data go as high 10 standard deviations away (std=10). In order to make sure we that these samples would not skew our analysis later, we can only drop them.</p>
							<pre class="code-block">def remove_outliers(df, feature, threshold):
	df_scaled = df.copy(deep=True)
	scaler = StandardScaler()
	df_scaled[[feature]] = scaler.fit_transform(df_scaled[[feature]])
	mask = abs(df_scaled[feature]) <= threshold
	return df[mask].reset_index(drop=True)

threshold = 3
for col in df_dataset.select_dtypes(include='number').columns:
	df_dataset = remove_outliers(df_dataset, col, threshold)</pre>
						</div>
						<div class="container">
							<h3>1.c. Ensuring format consistency</h3>
							<p>In order to ensure the validity and consistency of the data, a quick set of tests are conducted to find incorrectly-formatted data. To accomplish this, we created a mask with the correct format for each column and compared it with the dataset entries. As seen below we can see that the results show no formatting mistakes for all columns.</p>
							<pre class="code-block">import re

print("Checking # of incorrectly-formatted rows...")
# Check account type
account_type_mask = df_dataset['Account type'].isin(['Anonymous','Identified','Media'])
print(f"For column \"Account type\": {df_dataset[~account_type_mask].shape[0]}")

# Check date posted (DD/MM/YY HH:MM)
date_posted_pattern = re.compile(r'(0[1-9]|[1-2][0-9]|3[0-1])\/(0[1-9]|1[0-2])\/([0-9]{2}) (2[0-3]|[01]?[0-9]):[0-5][0-9]')
date_posted_mask = df_dataset['Date posted'].astype(str).str.match(date_posted_pattern)
print(f"For column \"Date posted\": {df_dataset[~date_posted_mask].shape[0]}")

# Check content type
content_type_mask = df_dataset['Content type'].isin(['Rational','Emotional','Transactional'])
print(f"For column \"Content type\": {df_dataset[~content_type_mask].shape[0]}")

# Check for valid whole numbers
whole_number_pattern = re.compile(r'^\d+$')
for col in ['Following', 'Followers', 'Likes', 'Replies', 'Retweets', 'Quote Tweets']:
	number_mask = df_dataset[col].astype(str).str.match(whole_number_pattern)
	print(f"For column \"{col}\": {df_dataset[~number_mask].shape[0]}")</pre>
							<figure style="text-align: center;">
								<img src="1c-output1.png" alt="">
								<figcaption>Output of the codeblock</figcaption>
							</figure>
						</div>
						<div class="container">
							<h3>1.d. Categorical data encoding</h3>
							<p>Looking at our remaining columns, we can observe that there are two categorical vairables, `Account type` and `Content type`. In order to use the following variable later on, we will need to convert these columns to numerical data. To accomplish this, we perform one-hot encoding on both categories.</p>
							<pre class="code-block"># One-hot encode Account Type column
account_type_dummies = pd.get_dummies(df_dataset['Account type'], prefix='Account Type')
df_dataset = pd.concat([df_dataset, account_type_dummies], axis=1)

# One-hot encode Content Type column
content_type_dummies = pd.get_dummies(df_dataset['Content type'], prefix='Content Type')
df_dataset = pd.concat([df_dataset, content_type_dummies], axis=1)

print(df_dataset.columns)</pre>
							<figure style="text-align: center;">
								<img src="1d-output1.png" alt="">
								<figcaption>Columns of the dataframe</figcaption>
							</figure>
							<p>This will make it easier to perform analysis and modeling with these variables later on, espcially beside other numerical data.</p>
						</div>
						<div class="container">
							<h3>1.e. Natural Language Processing</h3>
							<p>Now that we have made sure that our data set has no blemishes, we can begin with the processing. We make use of the NLP (Natural Language Processing) module found within Python in order for us to turn our dataset to a more structured and workable set</p>
							<p>We begin our process by 'cleaning' the dataset and transforming special symbols such as emojis into words, as the usage of emojis may provide extra context to the tweets they are being used in.</p>
							<pre class="code-block">import pandas as pd
import re
import copy
import nltk

# Handle Emojis [2]
url_emoji = "https://drive.google.com/uc?id=1G1vIkkbqPBYPKHcQ8qy0G2zkoab2Qv4v"
df_emoji = pd.read_pickle(url_emoji)
df_emoji = {v: k for k, v in df_emoji.items()}

def emoji_to_word(text):
	for emot in df_emoji:
	text = re.sub(r'('+emot+')', "_".join(df_emoji[emot].replace(",","").replace(":","").split()), text)
	return text

# Handle Emoticons [2]
url_emote = "https://drive.google.com/uc?id=1HDpafp97gCl9xZTQWMgP2kKK_NuhENlE"
df_emote = pd.read_pickle(url_emote)

def emote_to_word(text):
	for emot in df_emote:
		text = re.sub(u'('+emot+')', "_".join(df_emote[emot].replace(",","").split()), text)
		text = text.replace("<3", "heart" ) # not included in emoticons database
	return text

texts = copy.deepcopy(df_dataset['Tweet'])

texts = [emoji_to_word(t) for t in texts]
texts = [emote_to_word(t) for t in texts]</pre>
							<p>after converting the emojis, we made use of a new array called `texts` which we used to store the new tweets as we wish to turn all the words into lowercase in order to make the dataset easier to work with.</p>
							<pre class="code-block">import string

# convert to lowercase
texts = [t.lower() for t in texts]

# replace tuob and suob with steam
texts = [t.replace('tuob', 'steam').replace('suob', 'steam') for t in texts]

# remove punctuation
texts = [t.translate(str.maketrans('', '', string.punctuation)) for t in texts]
</pre>
							<p>You may have noticed that we included a line of code that replaced `tuob` or `suob` with `steam`. This was done by us as a sort of bandaid solution as the translator was either ignoring the word entirely or misreading the word as `subo` leading to incorrect translation.</p>
							<p>In order to maximize the use of the NLP module, we decided to translate the tweets first from Tagalog to English as the module was not optimized to handle tweets in Tagalog.</p>
							<pre class="code-block"># Removing stopwords might be tedious for multilingual texts
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# CHEAP SOLUTION: translate texts to English (this is not 100% accurate)
from googletrans import Translator

# translate to English
translator = Translator()
texts_en = [t.text for t in translator.translate(texts, src='tl', dest='en')]</pre>
							<p>Now that we converted the dataset into English, we could know start with actually structuring the data. First we started by tokenizing the data. Tokenizing is when we conviently split up text word by word. This allowed us to work with smaller pieces of data that were still meaningful even outside of context of the rest of the text. </p>
							<p>After tokenizing, we also made sure to remove the stopwords in our dataset. Stopwords are pretty much the words we don't really want to care about, so we filter them out of our data frame.</p>
							<pre class="code-block">texts_tok = []
for text in texts_en:
	# tokenize the text into words
	words = word_tokenize(text)

	# remove stopwords
	filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]

	# convert back into sentence
	filtered_sentence = ' '.join(filtered_words)
	texts_tok.append(filtered_sentence)</pre>
							<p>The process of tokenizing and stopwords removal was similar to our earlier methods, as you can see with the use of a new array called `texts_tok`.</p>
							<p>With the data now easier to work with, we simplified it further with Stemming and Lemmatization. Stemming is when you strip a word down to its root word. Kind of like turning a fraction into its simplest form. Lemmatization is like stemming but will give you a complete word that makes sense when you read it instead of a fragment of a word.</p>
							<p>We accomplished stemming and lemmatization by making use of separate variables called `stemmer` and `lemmatizer` respectively, which was used in the `stem_lem` function for the process of stemming/lemmatization. </p>
							<pre class="code-block">from nltk.stem import PorterStemmer, WordNetLemmatizer

# Initialize the stemmer and lemmatizer
stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()

texts_stem, texts_lem = [], []

def stem_lem(text):
	words = text.split()

	# Stem each word
	stemmed_words = [stemmer.stem(word) for word in words]
	
	# Lemmatize each word
	lemmatized_words = [lemmatizer.lemmatize(word) for word in words]
	
	# Return the stemmed and lemmatized words as a tuple
	texts_stem.append(stemmed_words)
	texts_lem.append(lemmatized_words)

	return (stemmed_words, lemmatized_words)


# Process each text in the array
processed_texts = [stem_lem(t) for t in texts_tok]


df_sl = pd.DataFrame({'Original': df_filt['Tokenized'], 'Stemmed': texts_stem, 'Lemmatized': texts_lem})
df_sl.style.set_properties(**{'text-align': 'left'})</pre>
							<figure>
								<img src="1e-output1.png" alt="" style="width:100%;">
								<figcaption>First 10 rows of the new dataframes</figcaption>
							</figure>
							<p>The final result from all the processing was the creation of a final dataframe called `df_sl` and this dataframe was used in getting the common `stemmed` and `lemmatized` words that gave us an insight as to which "cure" was most prevalent among the tweets.</p>
							<pre class="code-block">stemm_freq = df_sl['Stemmed'].explode().value_counts()
stemm_freq[:30].to_frame().style</pre>
							<figure style="text-align: center;">
								<img src="1e-output2.png" alt="">
								<figcaption>Most common words from the Stemmed dataframe</figcaption>
							</figure>
							<pre class="code-block">lemm_freq = df_sl['Lemmatized'].explode().value_counts()
lemm_freq[:30].to_frame().style</pre>
							<figure style="text-align: center;">
								<img src="1e-output3.png" alt="">
								<figcaption>Most common words from the Lemmatized dataframe</figcaption>
							</figure>
							<p>From the results, it was concluded that `steam` in this case `tuob` or `suob` was the most talked about "cure" for COVID, followed by `ginger`, `lemon`, `salt` and lastly, `vitamins`.</p>
						</div>
						<div class="container">
							<h3>1.f. Time series analysis binning</h3>
							<p>In order to do a time series analysis of our data, specifically the `Date posted` column, there is the option to either interpolate or bin the time points. However given the large range of time in which the data points are collected (2020-2022) and the small size of the dataset, binning is a much more feasible method. 14-day binning and monthly binning were chosen as the intervals. Given the limited dataset, monthly binning has a higher change of providing a clear distinction of spikes and peaks, while 14-day binning would make identifying which specific events (if there are any) may have resulted in the spike/peak. The process of binning can be found with the visualization of the time series thorough line plots.</p>
						</div>
					</div>
					<div class="container" id="visualization" style="text-align:left; margin-left: 40px;">
						<h3>2. Visualization</h3>
						<p>Now we can explore our data by visualizing its features.</p>
						<div class="container">
							<h3>2.a. Bar Plot</h3>
							<p>The first thing we are interested in looking into is finding possible connections between `Account Type` and `Content Type`. To answer this question, we create a Grouped Barplot that shows the number of samples for each `Content Type` grouped by `Account Type`.</p>
							<pre class="code-block"># Group the DataFrame by 'Account type' and 'Content type' and count the number of occurrences
df_count = df_dataset.groupby(['Account type', 'Content type'])['Content type'].count().reset_index(name='Count')

# Create a nested bar chart with Plotly
fig = px.bar(df_count, x="Account type", y="Count", color="Content type", barmode="group")

# Customize the layout of the chart
fig.update_layout(
	title="Number of Samples per Content Type by Account Type",
	xaxis_title="Account Type",
	yaxis_title="Count",
	legend_title="Content Type",
	font=dict(
		family="Arial",
		size=14,
		color="#333333"
	)
)

# Show the chart
fig.show()</pre>
							<figure>
								<embed type="text/html" src="bar.html" style="width: 100%; height: 500px;"> 
								<figcaption style="margin-top: -3em;">Bar graph visualization</figcaption>
							</figure>
							<p>The resulting graph shows some interesting results. The most obvious result is that `Emotional` tweets far outnumber `Rational`. `Transactional` tweets can also be seen to be very rare, with only one instance present. Additionally, most mis/disinformation comes from `Anonymous` account types, followed by `Identified`, and finally `Media` with one instance.</p>
							<p>A more notable observation is the distribution and ratio of `Emotional` and `Rational` tweets for `Anonymous` and `Identified`. `Identified` accounts can be seen to have close to a 2:1 split for `Emotional` and `Rational` tweets, however `Anonymous` tweets have a significantly higher ratio close to 5:1. This uneven ratio may suggest that `Anonymous` accounts are more likely to post mis/disinformation tweets `Emotionally`.</p>
						</div>
						<div class="container">
							<h3>2.b. Scatterplots</h3>
							<p>Next, we want to look into the distribution of numerical features such as `Following`, `Followers`, `Likes`, `Replies`, `Retweets`, `Quote Tweets` among `Account Types` using a Scatter Plot Matrix plot to find possible relationships between them.</p>
							<pre class="code-block"># Define the categorical and numerical features
feat_cat = ['Account Type_Anonymous', 'Account Type_Identified', 'Account Type_Media', 'Content Type_Emotional', 'Content Type_Rational', 'Content Type_Transactional']
feat_num = ['Following', 'Followers', 'Likes', 'Replies', 'Retweets', 'Quote Tweets']</pre>
							<pre class="code-block">import matplotlib.pyplot as plt
import seaborn as sns

# Set plot styling
sns.set(rc={'figure.figsize':(16,9)})
sns.set_theme(style="darkgrid")

# Plot the distribution of numerical features
g = sns.pairplot(data=df_dataset[feat_num+['Account type']], hue='Account type')
g.fig.suptitle("Twitter Data - Numerical Features", fontsize=18, y=1.05) # y: vertical position of title
plt.show()</pre>
							<figure>
								<img src="2b-output1.png" alt="" style="width: 100%;">
								<figcaption>Scatterplot visualization</figcaption>
							</figure>
							<p>Looking in the resulting plot, there no standout patterns can be observe. `Anonymous` and `Identified` `Account Types` are scattered randomly. Additionally, `Media` `Account Types` may seem to be missing in the scatter plots due to only having one sample in the entirety of the dataset, as seen in the bar plot.</p>
						</div>
						<div class="container">
							<h3>2.c. Heat Map</h3>
							<p>We also want to check if there are any correlations between the numerical features. We use a heat map in order to visualize possible correlations between features.</p>
							<pre class="code-block"># Correlation plot (heat map)
import plotly.express as px

num_features = ['Following','Followers', 'Likes', 'Replies', 'Retweets']
corr = df_dataset[num_features].corr() # Use Spearman for non-linear corr: (method='spearman')

fig = px.imshow(corr,
		color_continuous_scale='RdBu',
		zmin=-1,
		zmax=1,
		labels=dict(x='Features', y='Features', color='Correlation'),
		x=corr.columns,
		y=corr.columns)
fig.show()</pre>
							<figure style="text-align: center;">
								<embed type="text/html" src="heatmap.html" style="width: 600px; height: 500px;">
								<figcaption style="margin-top: -3em;">Heatmap visualization</figcaption>
							</figure>
							<p>Looking at the resulting heat map, we can see that there is little correlation between the numerical features. The numerical features with the greatest correlation are `Following` and `Followers`, which may be due to the fact that the more you follow other users, the more likely that others may follow back, cause the said relation. Aside from that, there are no other strong correlations that can be observed.</p>
						</div>
						<div class="container">
							<h3>2.d. Line Plot (Time-series)</h3>
							<p>The last thing we want to look into are possible trends are present in mis/disinformation. To do this, we create two line plots, one for 14 day binning and another for monthly binning.</p>
							<pre class="code-block">df_dataset['Date posted'] = pd.to_datetime(df_dataset['Date posted'])
df_dataset_14day = df_dataset.groupby(pd.Grouper(key='Date posted', freq='14D',convention='start')).size()

# Convert the pandas series to a DataFrame
df_dataset_14day = df_dataset_14day.to_frame(name='14 Day Tweet Count')

# Reset the index and rename the column to 'Date posted'
df_dataset_14day = df_dataset_14day.reset_index().rename(columns={'Date posted': 'Date posted', 0: '14 Day Tweet Count'})

# Create a line plot using Plotly
fig = px.line(df_dataset_14day, x='Date posted', y='14 Day Tweet Count', title='14 Day Binning Tweet Count')
fig.show()
</pre>
							<figure>
								<embed type="text/html" src="line-14day.html" style="width: 100%; height: 500px;"> 
								<figcaption style="margin-top: -3em;">Line plot visualization (14 day binning)</figcaption>
							</figure>
							<pre class="code-block">df_dataset['Date posted'] = pd.to_datetime(df_dataset['Date posted'])
df_dataset_monthly = df_dataset.groupby(pd.Grouper(key='Date posted', freq='1M',convention='start')).size()

# Convert the pandas series to a DataFrame
df_dataset_monthly = df_dataset_monthly.to_frame(name='Monthly Tweet Count')

# Reset the index and rename the column to 'Date posted'
df_dataset_monthly = df_dataset_monthly.reset_index().rename(columns={'Date posted': 'Date posted', 0: 'Monthly Tweet Count'})

# Create a line plot using Plotly
fig = px.line(df_dataset_monthly, x='Date posted', y='Monthly Tweet Count', title='Monthly Binning Tweet Count')
fig.show()
</pre>
							<figure>
								<embed type="text/html" src="line-1month.html" style="width: 100%; height: 500px;"> 
								<figcaption style="margin-top: -3em;">Line plot visualization (Monthly binning)</figcaption>
							</figure>
							<p>Looking at our time series data, we can quickly observe that there are (3) major peaks in both the 14 day binning and monthly binning. Most notably, when we compare the monthly binning side-by-side to the number of active cases of COVID-19, we can observe that the spikes happen at around the same time.</p>
							<figure style="text-align: center;">
								<img src="2d-output1.png" alt="">
								<figcaption>Active COVID cases line graph (Philippines)</figcaption>
							</figure>
						</div>
					</div>
					<footer>
						<p>Want a more detailed view?</p>
						<a href="https://colab.research.google.com/drive/1tcgCDNkg-jZN13Bc0dKArLcq4YV9d928?usp=sharing" class="button large scrolly" target="_blank">Click here!</a>
					</footer>
				</div>
			</article>

			<!-- Methods -->
			<article id="methods" class="wrapper style2">
				<div class="container">
					<header>
						<h2>Let's talk about our data science methodology.</h2>
						<p>Proin odio consequat  sapien vestibulum consequat lorem dolore feugiat.</p>
					</header>
					<div class="row">
						<div class="col-6 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic02.jpg" alt="" /></a>
								<h3><a href="#">Data Preprocessing</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
						<div class="col-6 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic01.jpg" alt="" /></a>
								<h3><a href="#">Machine Learning</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
					</div>
					<footer>
						<p>Lorem ipsum dolor sit sapien vestibulum ipsum primis?</p>
					</footer>
				</div>
			</article>

			<!-- Results -->
			<article id="results" class="wrapper style1">
				<div class="container">
					<header>
						<h2>Here's what we found out.</h2>
						<p>Proin odio consequat  sapien vestibulum consequat lorem dolore feugiat.</p>
					</header>
					<div class="row">
						<div class="col-6 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic02.jpg" alt="" /></a>
								<h3><a href="#">Results</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
						<div class="col-6 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic01.jpg" alt="" /></a>
								<h3><a href="#">Results</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
					</div>
					<footer>
						<p>Want to learn more? Take a look at our source codes.</p>
						<a href="https://github.com/jltsang/COVID-Alternative-Cures-Misinformation" class="button large scrolly" target="_blank">Github Repo</a>
					</footer>
				</div>
			</article>

		<!-- Team -->
			<article id="team" class="wrapper style2">
				<div class="container medium">
					<header>
						<h2>Team Members</h2>
					</header>
					<section class="box style1">
						<div class="column">
							<div class="col-4 col-6-medium col-12-small">
								<h3>Francis Mamuyac Albarracin</h3>
								<a href="mailto:fmalbarracin@up.edu.ph">fmalbarracin@up.edu.ph</a>
							</div>
							<div class="col-8 col-6-medium col-12-small">
								<p>Hello! Iâ€™m Francis Mamuyac Albarracin, currently a 3rd year BS Computer Science student at the University of the Philippines - Diliman. Iâ€™ve always been interested in technology ever since I was a child and am always looking to learn more about all the different technologies and gadgets that we use today. Some of my hobbies include learning Japanese, basketball, incremental improvement, and optimization ðŸ™‚.</p>
							</div>	
						</div>
					</section>
					<section class="box style1">
						<div class="column">
							<div class="col-4 col-6-medium col-12-small">
								<h3>Zachary R. Nabong</h3>
								<a href="mailto:zrnabong@up.edu.ph">zrnabong@up.edu.ph</a>
							</div>
							<div class="col-8 col-6-medium col-12-small">
								<p>Hello! Iâ€™m Zachary R. Nabong, and I am a 2nd year BS Computer Science student at University of the Philippines - Diliman. Coding has always been something that has interested me, more specifically game development and data science. My hobbies include playing video games such as CSGO, Valorant, Rainbow Six and Dota 2.</p>
							</div>	
						</div>
					</section>

					<section class="box style1">
						<div class="column">
							<div class="col-4 col-6-medium col-12-small">
								<h3>Jeremy King L. Tsang</h3>
								<a href="mailto:jltsang1@up.edu.ph">jltsang1@up.edu.ph</a>
							</div>
							<div class="col-8 col-6-medium col-12-small">
								<p>Hi! Iâ€™m Jeremy King L. Tsang, a 4th year BS Computer Science student at University of the Philippines - Diliman. I am currently an undergraduate researcher at Service Science and Software Engineering Laboratory (S3), where I am focusing on identifying and improving student recruitment systems of higher education institutions in the Philippines. In my free time, I am fond of reading light novels online and practicing to play the piano. </p>
							</div>	
						</div>
					</section>
					<header>
						<h2>We'd like to hear from you.</h2>
						<p>Please fill out this <a href="https://forms.gle/e5AFmiH5HtX4tKSx8" target="_blank">form</a> to send us your comments and suggestions.</p>
					</header>
					<!-- <div class="row">
						<div class="col-12">
							<form method="post" action="#">
								<div class="row">
									<div class="col-6 col-12-small">
										<input type="text" name="name" id="name" placeholder="Name" />
									</div>
									<div class="col-6 col-12-small">
										<input type="text" name="email" id="email" placeholder="Email" />
									</div>
									<div class="col-12">
										<input type="text" name="subject" id="subject" placeholder="Subject" />
									</div>
									<div class="col-12">
										<textarea name="message" id="message" placeholder="Message"></textarea>
									</div>
									<div class="col-12">
										<ul class="actions">
											<li><input type="submit" value="Send Message" /></li>
											<li><input type="reset" value="Clear Form" class="alt" /></li>
										</ul>
									</div>
								</div>
							</form>
						</div> -->
						<!-- <div class="col-12">
							<hr />
							<h3>Find me on ...</h3>
							<ul class="social">
								<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
								<li><a href="#" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
								<li><a href="#" class="icon brands fa-tumblr"><span class="label">Tumblr</span></a></li>
								<li><a href="#" class="icon brands fa-google-plus"><span class="label">Google+</span></a></li>
								<li><a href="" class="icon brands fa-github"><span class="label">Github</span></a></li>
								
								<li><a href="#" class="icon solid fa-rss"><span>RSS</span></a></li>
								<li><a href="#" class="icon brands fa-instagram"><span>Instagram</span></a></li>
								<li><a href="#" class="icon brands fa-foursquare"><span>Foursquare</span></a></li>
								<li><a href="#" class="icon brands fa-skype"><span>Skype</span></a></li>
								<li><a href="#" class="icon brands fa-soundcloud"><span>Soundcloud</span></a></li>
								<li><a href="#" class="icon brands fa-youtube"><span>YouTube</span></a></li>
								<li><a href="#" class="icon brands fa-blogger"><span>Blogger</span></a></li>
								<li><a href="#" class="icon brands fa-flickr"><span>Flickr</span></a></li>
								<li><a href="#" class="icon brands fa-vimeo"><span>Vimeo</span></a></li>
								
							</ul>
							<hr />
						</div> -->
					</div>
					<footer>
						<ul id="copyright">
							<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</footer>
				</div>
			</article>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
